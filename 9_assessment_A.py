import json
import os
import re
import difflib
import pandas as pd
import shutil
from typing import Dict, Any, List, Union, Literal, Optional
import traceback
from multiprocessing import Process, Queue
import queue  # For queue.Empty exception

# =============================================================================
# 1. Import and Configure External Modules
# =============================================================================
try:
    import reconstruction
    RECONSTRUCTION_MODULE_AVAILABLE = True
    # Key: Disable interactive display in the reconstruction module for automated execution.
    reconstruction.display_available = False
    print("Successfully imported and configured the reconstruction module.")
except ImportError:
    print("Warning: reconstruction.py not found. Model reconstruction will be unavailable.")
    RECONSTRUCTION_MODULE_AVAILABLE = False

# Set environment variable for offscreen rendering BEFORE any OCC/Display modules are imported.
os.environ['PYTHONOCC_OFFSCREEN_RENDERING'] = "1"

# Attempt to import pydantic for data validation.
try:
    from pydantic import BaseModel, ValidationError, Field
    PYDANTIC_AVAILABLE = True
except ImportError:
    PYDANTIC_AVAILABLE = False
    print("Warning: pydantic library not found. 0.75 score validation for ACCcmd will be unavailable.")

# Attempt to import python-occ-core for geometric operations.
try:
    from OCC.Core.TopoDS import TopoDS_Shape
    from OCC.Display.SimpleGui import init_display
    from OCC.Core.Quantity import Quantity_Color, Quantity_TOC_RGB, Quantity_NOC_BLACK, Quantity_NOC_GRAY
    from OCC.Core.Aspect import Aspect_TOL_SOLID
    from OCC.Core.Prs3d import Prs3d_LineAspect
    from OCC.Core.Bnd import Bnd_Box
    from OCC.Core.BRepBndLib import brepbndlib_Add
    OCC_AVAILABLE = True
except ImportError:
    OCC_AVAILABLE = False
    print("Warning: python-occ-core library not found. Image saving and BBox calculation will be unavailable.")

# Attempt to import Pillow for image stitching.
try:
    from PIL import Image
    PIL_AVAILABLE = True
    print("Successfully imported Pillow (PIL) for image stitching.")
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: Pillow (PIL) library not found. Image stitching will be unavailable.")

# =============================================================================
#  2. Pydantic Schema for JSON Validation
# =============================================================================
if PYDANTIC_AVAILABLE:
    # Pydantic models define the expected structure of the CAD data.
    # This allows for strict validation of the JSON generated by the LLM.
    class Point3D(BaseModel):
        type: Literal["Point3D"]
        x: float
        y: float
        z: float

    class Vector3D(BaseModel):
        type: Literal["Vector3D"]
        x: float
        y: float
        z: float
        length: Optional[float] = None

    class SketchLine(BaseModel):
        type: Literal["SketchLine"]
        start_point: str
        end_point: str

    class SketchCircle(BaseModel):
        type: Literal["SketchCircle"]
        center_point: str
        radius: float

    CurveType = Union[SketchLine, SketchCircle]

    class ProfileCurve_Line3D(BaseModel):
        type: Literal["Line3D"]
        curve: str
        start_point: Point3D
        end_point: Point3D

    class ProfileCurve_Circle3D(BaseModel):
        type: Literal["Circle3D"]
        curve: str
        center_point: Point3D
        normal: Vector3D
        radius: float

    ProfileCurveType = Union[ProfileCurve_Line3D, ProfileCurve_Circle3D]

    class ProfileLoop(BaseModel):
        is_outer: bool
        profile_curves: List[ProfileCurveType]

    class Profile(BaseModel):
        loops: List[ProfileLoop]

    class Transform(BaseModel):
        origin: Point3D
        x_axis: Vector3D
        y_axis: Vector3D
        z_axis: Vector3D

    class Sketch(BaseModel):
        type: Literal["Sketch"]
        points: Dict[str, Point3D]
        curves: Dict[str, CurveType]
        profiles: Dict[str, Profile]
        transform: Transform

    class ExtrudeProfile(BaseModel):
        profile: str
        sketch: str

    class Distance(BaseModel):
        value: float

    class DistanceExtentDefinition(BaseModel):
        distance: Distance
        type: Literal["DistanceExtentDefinition"]

    class ProfilePlaneStartDefinition(BaseModel):
        type: Literal["ProfilePlaneStartDefinition"]

    ExtrudeOperationType = Literal[
        "NewBodyFeatureOperation", "JoinFeatureOperation", "CutFeatureOperation", "IntersectFeatureOperation"]
    ExtentType = Literal["OneSideFeatureExtentType", "TwoSidesFeatureExtentType", "SymmetricFeatureExtentType"]

    class ExtrudeFeature(BaseModel):
        type: Literal["ExtrudeFeature"]
        profiles: List[ExtrudeProfile]
        operation: ExtrudeOperationType
        extent_type: ExtentType
        start_extent: ProfilePlaneStartDefinition
        extent_one: DistanceExtentDefinition
        extent_two: Optional[DistanceExtentDefinition] = None

    EntityType = Union[Sketch, ExtrudeFeature]

    class CADModel(BaseModel):
        entities: Dict[str, EntityType]
        class Config: extra = 'forbid'

    # Rebuild models to ensure forward references are resolved correctly.
    Sketch.model_rebuild()
    CADModel.model_rebuild()

# =============================================================================
#  3. Worker function for multiprocessing
# =============================================================================
def reconstruction_worker(q: Queue, data_to_reconstruct: Dict[str, Any]):
    """
    A worker function to run the model reconstruction in a separate process.
    This prevents the main process from crashing due to errors in the reconstruction library.
    """
    try:
        import reconstruction
        reconstruction.display_available = False
        shape = reconstruction.build_model_from_data(data_to_reconstruct)
        q.put(shape)
    except Exception as e:
        q.put(e)

# =============================================================================
#  4. Core Evaluation & Processing Functions
# =============================================================================
def save_shape_as_image(display, shape: TopoDS_Shape, image_path: str, part_id: str, reference_image_dir: str):
    """
    Saves a representation of the shape as a PNG image.
    If a reference image is found, it stitches it with the newly generated image for comparison.
    """
    if not OCC_AVAILABLE or not shape or shape.IsNull() or display is None: return

    # --- Part 1: Generate the new image and save it temporarily ---
    temp_image_path = image_path.replace(".png", "_temp_generated.png")
    try:
        display.EraseAll()
        # Set color to brown
        shape_color = Quantity_Color(0.545, 0.271, 0.075, Quantity_TOC_RGB)
        # Set to semi-transparent
        ais_objects = display.DisplayShape(shape, color=shape_color, update=False, transparency=0.6)

        if not isinstance(ais_objects, list): ais_objects = [ais_objects]
        if ais_objects:
            for ais_solid in ais_objects:
                if ais_solid:
                    ais_solid.SetDisplayMode(1)  # Shaded mode
                    drawer = ais_solid.Attributes()
                    drawer.SetFaceBoundaryDraw(True)
                    line_aspect = Prs3d_LineAspect(Quantity_Color(Quantity_NOC_BLACK), Aspect_TOL_SOLID, 2.5)
                    drawer.SetLineAspect(line_aspect)
        display.FitAll()
        display.View.Redraw()

        if not display.View.Dump(str(temp_image_path)):
            print(f"      -> FAILED to save temporary image: {temp_image_path}")
            return
    except Exception as e:
        print(f"      -> An exception occurred while generating the shape image: {e}")
        traceback.print_exc()
        return

    # --- Part 2: Stitch with reference image if available ---
    if not PIL_AVAILABLE:
        os.rename(temp_image_path, image_path)
        print(f"      -> Pillow not available. Saved single image to: {image_path}")
        return

    reference_path = os.path.join(reference_image_dir, f"{part_id}.png")

    try:
        if not os.path.exists(reference_path):
            os.rename(temp_image_path, image_path)
            print(f"      -> Reference image not found at '{reference_path}'. Saving generated image only.")
            return

        generated_img = Image.open(temp_image_path)
        reference_img = Image.open(reference_path)

        # Ensure both images have the same height for clean stitching.
        h_gen, h_ref = generated_img.height, reference_img.height
        if h_gen != h_ref:
            target_height = max(h_gen, h_ref)
            if generated_img.height != target_height:
                ratio = target_height / generated_img.height
                generated_img = generated_img.resize((int(generated_img.width * ratio), target_height), Image.LANCZOS)
            if reference_img.height != target_height:
                ratio = target_height / reference_img.height
                reference_img = reference_img.resize((int(reference_img.width * ratio), target_height), Image.LANCZOS)

        total_width = reference_img.width + generated_img.width
        max_height = reference_img.height

        # Create a new blank image to paste onto, supporting RGBA for transparency.
        combined_img = Image.new('RGBA', (total_width, max_height))

        # Paste reference on the left, new image on the right.
        combined_img.paste(reference_img, (0, 0))
        combined_img.paste(generated_img, (reference_img.width, 0))

        combined_img.save(image_path)
        print(f"      -> Successfully saved combined image to: {image_path}")

    except Exception as e:
        print(f"      -> An exception occurred during image stitching: {e}")
        # Fallback to saving just the generated image.
        if os.path.exists(temp_image_path):
            os.rename(temp_image_path, image_path)
    finally:
        # Clean up the temporary file.
        if os.path.exists(temp_image_path):
            os.remove(temp_image_path)

def load_ground_truth_bbox(file_path: str) -> Dict[str, Dict[str, float]]:
    """Loads ground truth bounding box data from the description file."""
    bbox_data = {}
    if not os.path.exists(file_path):
        print(f"Warning: Bounding box description file not found at '{file_path}'. Cannot calculate BBox similarity.")
        return bbox_data
    bbox_regex = re.compile(r"X=([\d.]+),Y=([\d.]+),Z=([\d.]+)")
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split(';', 3)
            if len(parts) == 4:
                part_id, _, _, bbox_str = parts
                match = bbox_regex.match(bbox_str)
                if match:
                    x, y, z = map(float, match.groups())
                    bbox_data[part_id] = {"X": x, "Y": y, "Z": z}
    print(f"Successfully loaded ground truth bounding boxes for {len(bbox_data)} parts.")
    return bbox_data

def get_shape_bbox_dimensions(shape: TopoDS_Shape) -> Optional[Dict[str, float]]:
    """Calculates the dimensions of a shape's bounding box."""
    if not shape or shape.IsNull() or not OCC_AVAILABLE: return None
    bbox = Bnd_Box()
    try:
        brepbndlib_Add(shape, bbox, True)
        if bbox.IsVoid(): return None
        xmin, ymin, zmin, xmax, ymax, zmax = bbox.Get()
        return {"X": xmax - xmin, "Y": ymax - ymin, "Z": zmax - zmin}
    except Exception as e:
        print(f"      -> An exception occurred during BBox calculation: {e}")
        return None

def calculate_bbox_similarity(recon_dims: Dict[str, float], truth_dims: Dict[str, float]) -> Dict[str, float]:
    """Calculates the similarity between two bounding boxes based on their dimensions."""
    sims = {}
    recon_sorted = sorted(recon_dims.values())
    truth_sorted = sorted(truth_dims.values())
    total_sim = 0
    for i in range(3):
        d_recon, d_truth = recon_sorted[i], truth_sorted[i]
        denominator = max(d_recon, d_truth)
        sim = 1 - (abs(d_recon - d_truth) / denominator) if denominator > 1e-6 else 1.0
        sims[f'dim_{i + 1}_sim'] = sim
        total_sim += sim
    sims['bbox_avg_sim'] = total_sim / 3
    return sims

def clear_previous_results(responses_dir, csv_path):
    """Clears directories and files from previous evaluation runs."""
    print("Clearing previous evaluation results...")
    if os.path.exists(responses_dir):
        try:
            shutil.rmtree(responses_dir)
            print(f"  -> Successfully deleted directory: {responses_dir}")
        except OSError as e:
            print(f"  -> Error deleting directory {responses_dir}: {e.strerror}")
    if os.path.exists(csv_path):
        try:
            os.remove(csv_path)
            print(f"  -> Successfully deleted file: {csv_path}")
        except OSError as e:
            print(f"  -> Error deleting file {csv_path}: {e.strerror}")
    print("Cleanup complete.")

def repair_json_structure(s: str) -> str:
    """Attempts to repair a potentially incomplete JSON string."""
    try:
        start_match = re.search(r'\{', s)
        if not start_match: return s
        s = s[start_match.start():]
        s_cleaned = re.sub(r',\s*(?=[}\]])', '', s) # Remove trailing commas
        stack = []
        pair_map = {'{': '}', '[': ']'}
        for char in s_cleaned:
            if char in pair_map:
                stack.append(char)
            elif char in pair_map.values():
                if stack and pair_map.get(stack[-1]) == char:
                    stack.pop()
        closing_chars = ""
        while stack:
            opening_char = stack.pop()
            closing_chars += pair_map[opening_char]
        return s_cleaned + closing_chars
    except Exception:
        return s

def calculate_acc_cmd_score(json_string: str, is_reconstructable: bool) -> float:
    """Calculates the Command Accuracy (ACCcmd) score based on a tiered validation system."""
    try:
        data = json.loads(json_string)
    except json.JSONDecodeError:
        return 0.00
    if not isinstance(data, dict):
        return 0.00
    # Tier 1: Pydantic validation (most strict)
    if PYDANTIC_AVAILABLE:
        try:
            CADModel.model_validate(data)
            return 1.00 if RECONSTRUCTION_MODULE_AVAILABLE and is_reconstructable else 0.75
        except ValidationError:
            pass # Fall through to next checks
    # Tier 2: Check for 'entities' dictionary
    if isinstance(data.get('entities'), dict):
        entities = data['entities']
        s_pat, e_pat = re.compile(r'^Sketch\d+$'), re.compile(r'^Extrude\d+$')
        if all(s_pat.match(k) or e_pat.match(k) for k in entities.keys()):
            sketch_entities = [e for e in entities.values() if isinstance(e, dict) and e.get('type') == 'Sketch']
            if not sketch_entities: return 0.25 # Has entities but no sketches
            # Tier 3: Check for required keys in sketch entities
            req_keys = {'points', 'curves', 'profiles', 'transform'}
            if all(req_keys.issubset(e.keys()) for e in sketch_entities):
                return 0.50
    return 0.25

def complete_sequence_by_definition_order(entities_data: Any) -> Dict[str, Any]:
    """Adds a 'sequence' key to the JSON data based on the order of entities."""
    if not isinstance(entities_data, dict):
        return {"entities": {}, "sequence": []}
    entities = entities_data.get("entities", {})
    if not isinstance(entities, dict):
        return {"entities": {}, "sequence": []}
    seq = [{"type": ed.get("type"), "entity": en} for en, ed in entities.items() if isinstance(ed, dict)]
    for i, item in enumerate(seq): item["index"] = i
    return {"entities": entities, "sequence": seq}

def get_canonical_string(json_string):
    """Converts a JSON string to a canonical form for consistent comparison."""
    try:
        return json.dumps(json.loads(json_string), sort_keys=True, separators=(',', ':'))
    except json.JSONDecodeError:
        return json_string

def calculate_string_similarity(str1, str2):
    """Calculates the ratio of similarity between two strings."""
    return difflib.SequenceMatcher(None, str1, str2).ratio()

def preprocess_responses_from_txt(results_file, output_dir):
    """Reads the raw model output file and saves each response as a separate JSON."""
    if not os.path.exists(results_file): return None
    os.makedirs(output_dir, exist_ok=True)
    part_ids = set()
    print(f"Preprocessing '{results_file}' and saving responses to '{output_dir}'...")
    with open(results_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line: continue
            parts = line.split(';', 2)
            if len(parts) != 3: continue
            part_id, _, responses_str = parts
            part_ids.add(part_id)
            responses = responses_str.split('<|>')
            for i, res_str in enumerate(responses):
                file_path = os.path.join(output_dir, f"{part_id}_{i + 1}.json")
                with open(file_path, 'w', encoding='utf-8') as f_out:
                    try:
                        repaired_str = repair_json_structure(res_str)
                        sanitized_res_str = repaired_str.replace('\\n', '\n')
                        data = json.loads(sanitized_res_str)
                        json.dump(data, f_out, indent=2, ensure_ascii=False)
                    except json.JSONDecodeError:
                        f_out.write(res_str)
    print("Preprocessing complete.")
    return part_ids

def generate_console_report(df: pd.DataFrame, total_parts_in_source: int):
    """Generates a visually appealing console report of the evaluation results."""
    if df.empty:
        print("\nNo valid records available for analysis. Report not generated.")
        return

    # --- Data Preparation ---
    evaluated_parts = len(df)
    avg_cmd = df['acc_cmd'].mean()
    avg_param = df['acc_param'].mean()

    success_df = df[df['acc_cmd'] == 1.00].copy()
    avg_bbox_sim = success_df['bbox_avg_sim'].mean() if 'bbox_avg_sim' in success_df.columns and success_df[
        'bbox_avg_sim'].notna().any() else 0.0

    dist = df['acc_cmd'].value_counts().sort_index(ascending=False)

    # --- Console Report ---
    print("\n" + "=" * 80)
    print(" " * 25 + "Model Performance Evaluation Report")
    print("=" * 80)
    print(f"| {'Overview':<76} |")
    print(f"| {'-' * 76} |")
    print(f"| Total Parts in Source: {total_parts_in_source:<10} | Evaluated Parts: {evaluated_parts:<27} |")
    print("=" * 80)
    print(f"| {'Core Metrics':<76} |")
    print(f"| {'-' * 76} |")
    print(f"| Average Command Accuracy (ACCcmd): {avg_cmd:<.4f}                                     |")
    print(f"| Average Parameter Similarity (ACCparam): {avg_param:<.4f}                               |")
    if avg_bbox_sim > 0:
        print(f"| Average BBox Similarity (BBox Sim): {avg_bbox_sim:<.4f}                                 |")
    print("=" * 80)
    print(f"| {'ACCcmd Score Distribution':<76} |")
    print(f"| {'-' * 76} |")
    print(f"| {'Score':<10} | {'Count':<10} | {'Percentage':<53} |")
    for score, count in dist.items():
        percent = (count / evaluated_parts) * 100 if evaluated_parts > 0 else 0
        print(f"| {score:<10.2f} | {count:<10} | {percent:<52.2f}% |")
    print("=" * 80)

# =============================================================================
#  5. Main Logic
# =============================================================================
def main():
    results_file = "batch_test_results_A.txt"
    ground_truth_dir = "compressed_json"
    responses_dir = "evaluation_responses_A"
    success_dir = os.path.join(responses_dir, "reconstruction_success")
    output_csv_path = os.path.join(responses_dir, "evaluation_details_acct.csv")
    bbox_file = "descriptions_for_compressed_json.txt"

    clear_previous_results(responses_dir, output_csv_path)
    part_ids_from_source = preprocess_responses_from_txt(results_file, responses_dir)
    if not part_ids_from_source:
        print(f"Error: Source results file '{results_file}' not found or is empty.")
        return

    bbox_ground_truth = load_ground_truth_bbox(bbox_file)

    display_context = None
    if OCC_AVAILABLE:
        try:
            print("[DEBUG] Attempting to initialize OCC Display...")
            display_context, _, _, _ = init_display()
            bg_color = Quantity_Color(245 / 255, 245 / 255, 245 / 255, Quantity_TOC_RGB)
            display_context.View.SetBackgroundColor(bg_color)
            print("[DEBUG] OCC Display initialized successfully.")
        except Exception as e:
            print(f"[DEBUG] Could not initialize OCC Display, image saving will be disabled. Error: {e}")
            display_context = None

    final_records = []
    print(f"\nFound {len(part_ids_from_source)} unique part IDs. Starting evaluation...")

    for part_id in sorted(list(part_ids_from_source)):
        gt_path = os.path.join(ground_truth_dir, f"{part_id}.json")
        if not os.path.exists(gt_path):
            print(f"  -> Warning: Ground truth for '{part_id}' not found. Skipping.")
            continue
        with open(gt_path, 'r', encoding='utf-8') as f_gt:
            canonical_gt_str = get_canonical_string(f_gt.read())

        part_evaluations = []
        for i in range(1, 4): # Check for up to 3 responses per part
            res_path = os.path.join(responses_dir, f"{part_id}_{i}.json")
            if not os.path.exists(res_path): continue
            with open(res_path, 'r', encoding='utf-8') as f_res:
                response_str = f_res.read()

            repaired_str = repair_json_structure(response_str).replace('\\n', '\n')
            json_data = None
            reconstructed_shape = None
            try:
                json_data = json.loads(repaired_str)
            except json.JSONDecodeError:
                pass

            completed_data = complete_sequence_by_definition_order(json_data)

            if isinstance(json_data, dict) and RECONSTRUCTION_MODULE_AVAILABLE:
                print(f"[DEBUG] Preparing to reconstruct model for part_id: {part_id}, attempt {i}")
                q = Queue()
                p = Process(target=reconstruction_worker, args=(q, completed_data))
                p.start()
                p.join(timeout=15) # Set a timeout for the reconstruction process

                if p.is_alive():
                    print(f"[DEBUG] Reconstruction for {part_id} timed out. Terminating process.")
                    p.terminate()
                    p.join()
                    reconstructed_shape = None
                elif p.exitcode != 0:
                    print(f"[DEBUG] Reconstruction process for {part_id} crashed with exit code {p.exitcode}.")
                    reconstructed_shape = None
                else:
                    try:
                        result = q.get_nowait()
                        if isinstance(result, Exception):
                            print(f"[DEBUG] Python exception in reconstruction worker for {part_id}: {result}")
                            reconstructed_shape = None
                        else:
                            reconstructed_shape = result
                    except queue.Empty:
                        print(f"[DEBUG] Reconstruction queue empty for {part_id} despite process finishing.")
                        reconstructed_shape = None
                print(
                    f"[DEBUG] Reconstruction finished for part_id: {part_id}. Shape is {'not None' if reconstructed_shape else 'None'}.")

            is_reconstructable = reconstructed_shape is not None
            acc_cmd = calculate_acc_cmd_score(repaired_str, is_reconstructable)
            acc_param = calculate_string_similarity(canonical_gt_str, get_canonical_string(repaired_str))
            part_evaluations.append({
                "part_id": part_id, "acc_cmd": acc_cmd, "acc_param": acc_param,
                "completed_response_data": completed_data, "response_str": repaired_str,
                "reconstructed_shape": reconstructed_shape
            })

        if not part_evaluations: continue
        # Select the best response for the part based on the highest scores.
        best_response = max(part_evaluations, key=lambda x: (x["acc_cmd"], x["acc_param"]))

        # If the best response was fully successful, calculate bbox similarity.
        if best_response['acc_cmd'] == 1.00:
            shape_to_save = best_response.get('reconstructed_shape')
            if shape_to_save:
                truth_dims = bbox_ground_truth.get(part_id)
                if truth_dims:
                    recon_dims = get_shape_bbox_dimensions(shape_to_save)
                    if recon_dims:
                        bbox_sims = calculate_bbox_similarity(recon_dims, truth_dims)
                        best_response.update(bbox_sims)
                        print(f"      -> BBox similarity for {part_id}: {bbox_sims['bbox_avg_sim']:.4f}")
                    else:
                        print(f"      -> Could not calculate BBox for reconstructed shape of {part_id}.")
                else:
                    print(f"      -> Ground truth BBox not found for {part_id}.")

        # Save the best response to a directory named after its score.
        score = best_response['acc_cmd']
        score_dir_name = f"{score:.2f}"
        target_dir = os.path.join(responses_dir, score_dir_name)
        os.makedirs(target_dir, exist_ok=True)
        output_path = os.path.join(target_dir, f"{part_id}.json")
        with open(output_path, 'w', encoding='utf-8') as f_out:
            try:
                data_to_save = best_response.get('completed_response_data', {}).get('entities')
                if data_to_save:
                    json.dump({"entities": data_to_save}, f_out, indent=2, ensure_ascii=False)
                else:
                    json.dump(json.loads(best_response['response_str']), f_out, indent=2, ensure_ascii=False)
            except (json.JSONDecodeError, AttributeError):
                f_out.write(best_response['response_str'])

        # If fully successful, also save JSON and image to the 'success' directory.
        if best_response['acc_cmd'] == 1.00:
            os.makedirs(success_dir, exist_ok=True)
            json_path = os.path.join(success_dir, f"{part_id}_success.json")
            with open(json_path, 'w', encoding='utf-8') as f_out:
                json.dump(best_response['completed_response_data'], f_out, indent=2, ensure_ascii=False)
            shape_to_save = best_response.get('reconstructed_shape')
            if shape_to_save and display_context:
                image_path = os.path.join(success_dir, f"{part_id}_success.png")
                print(f"[DEBUG] Saving image for part_id: {part_id} to {image_path}")
                reference_dir = "compressed_json"
                save_shape_as_image(display_context, shape_to_save, image_path, part_id, reference_dir)

        final_records.append(best_response)
        print(f"[DEBUG] Finished processing part_id: {part_id}\n")

    df = pd.DataFrame(final_records)

    generate_console_report(df, len(part_ids_from_source))

    if not df.empty:
        os.makedirs(responses_dir, exist_ok=True)
        csv_columns = ['part_id', 'acc_cmd', 'acc_param', 'bbox_avg_sim']
        df.to_csv(output_csv_path, index=False, columns=csv_columns)
        print(f"✅ Evaluation data saved to: '{os.path.abspath(output_csv_path)}'")
    else:
        print("\nEvaluation report not generated, no valid records.")


if __name__ == "__main__":
    import multiprocessing
    multiprocessing.freeze_support()

    if RECONSTRUCTION_MODULE_AVAILABLE:
        if hasattr(reconstruction, 'script_dir'):
            reconstruction.script_dir = os.path.dirname(os.path.abspath(__file__))
    main()
